/**
 * ü§ñ ENHANCED STEFAN AI HOOK
 * Integrerar assessment-data, hybrid AI-strategier och kontextuell promptbyggnad
 */

import { useState, useCallback } from 'react';
import { useAuth } from '@/providers/UnifiedAuthProvider';
import { useToast } from '@/hooks/use-toast';
import { supabase } from '@/integrations/supabase/client';
import { buildLovableAIPrompt, StefanPromptContext } from '@/utils/stefanAIPromptBuilder';

export interface EnhancedStefanResponse {
  message: string;
  contextUsed: StefanPromptContext;
  aiModel: 'openai' | 'gemini';
  responseTime: number;
  assessmentInsights: string[];
  recommendedActions: string[];
  confidence: number;
  fallbackUsed: boolean;
}

export interface StefanChatOptions {
  message: string;
  interactionType?: 'chat' | 'assessment_completion' | 'coaching_session' | 'progress_review';
  forceModel?: 'openai' | 'gemini' | 'auto';
  includeAssessmentContext?: boolean;
  generateRecommendations?: boolean;
}

/**
 * Enhanced Stefan AI Hook med assessment-integration och hybrid AI-strategi
 */
export const useEnhancedStefanAI = () => {
  const { user } = useAuth();
  const { toast } = useToast();
  const [loading, setLoading] = useState(false);
  const [lastResponse, setLastResponse] = useState<EnhancedStefanResponse | null>(null);

  /**
   * üéØ HUVUDFUNKTION: Kontextuell Stefan AI Chat
   * Integrerar assessment-data och anv√§nder hybrid AI-strategi
   */
  const enhancedStefanChat = useCallback(async (
    options: StefanChatOptions
  ): Promise<EnhancedStefanResponse | null> => {
    if (!user?.id) {
      toast({
        title: "Autentisering kr√§vs",
        description: "Du m√•ste vara inloggad f√∂r att chatta med Stefan AI",
        variant: "destructive"
      });
      return null;
    }

    setLoading(true);
    const startTime = Date.now();

    try {
      console.log('üöÄ Starting enhanced Stefan AI conversation');
      
      // 1. Bygg kontextuell prompt med assessment-data
      const promptContext = await buildLovableAIPrompt(
        user.id,
        options.message,
        options.interactionType || 'chat'
      );

      console.log('‚úÖ Built contextual prompt with assessment data');

      // 2. V√§lj AI-modell baserat p√• kontext och tillg√§nglighet
      const selectedModel = await selectOptimalAIModel(
        options.forceModel,
        options.message,
        promptContext
      );

      console.log(`ü§ñ Selected AI model: ${selectedModel}`);

      // 3. K√∂r AI-f√∂rfr√•gan med fallback-strategi
      const aiResponse = await executeAIRequestWithFallback(
        selectedModel,
        promptContext,
        options
      );

      // 4. Analysera och f√∂rb√§ttra responsen
      const enhancedResponse = await enhanceAIResponse(
        aiResponse,
        promptContext,
        options
      );

      const responseTime = Date.now() - startTime;

      const finalResponse: EnhancedStefanResponse = {
        message: enhancedResponse.message,
        contextUsed: promptContext,
        aiModel: aiResponse.modelUsed,
        responseTime,
        assessmentInsights: enhancedResponse.insights,
        recommendedActions: enhancedResponse.actions,
        confidence: enhancedResponse.confidence,
        fallbackUsed: aiResponse.fallbackUsed
      };

      // 5. Logga interaktionen f√∂r framtida f√∂rb√§ttringar
      await logStefanInteraction(finalResponse, options);

      setLastResponse(finalResponse);
      
      console.log(`‚úÖ Enhanced Stefan AI response completed in ${responseTime}ms`);
      
      return finalResponse;

    } catch (error) {
      console.error('‚ùå Enhanced Stefan AI error:', error);
      
      toast({
        title: "Stefan AI-fel",
        description: "Stefan har tekniska problem just nu. F√∂rs√∂k igen om en stund.",
        variant: "destructive"
      });

      // Fallback till standard Stefan om enhanced misslyckas
      return await fallbackToStandardStefan(options);
      
    } finally {
      setLoading(false);
    }
  }, [user, toast]);

  /**
   * üéØ ASSESSMENT-BASERAD FEEDBACK
   * Analyserar assessment-resultat och ger kontextuella r√•d
   */
  const generateAssessmentFeedback = useCallback(async (
    assessmentId: string,
    assessmentType: string
  ): Promise<EnhancedStefanResponse | null> => {
    if (!user?.id) return null;

    try {
      // H√§mta assessment-data
      const { data: assessment } = await supabase
        .from('assessment_rounds')
        .select('*')
        .eq('id', assessmentId)
        .single();

      if (!assessment) {
        throw new Error('Assessment not found');
      }

      // Skapa kontextuell feedback-prompt
      const feedbackMessage = `Jag har just slutf√∂rt en ${assessmentType}-assessment. 
Resultat: ${JSON.stringify(assessment.scores, null, 2)}
Kommentarer: ${assessment.comments || 'Inga kommentarer'}

Ge mig personlig feedback och n√§sta steg baserat p√• mina resultat och min utvecklingshistorik.`;

      return await enhancedStefanChat({
        message: feedbackMessage,
        interactionType: 'assessment_completion',
        includeAssessmentContext: true,
        generateRecommendations: true
      });

    } catch (error) {
      console.error('Error generating assessment feedback:', error);
      return null;
    }
  }, [user, enhancedStefanChat]);

  /**
   * üéØ PROGRESS REVIEW
   * Skapar periodiska utvecklings√∂versikter
   */
  const generateProgressReview = useCallback(async (
    timeframe: 'weekly' | 'monthly' | 'quarterly' = 'weekly'
  ): Promise<EnhancedStefanResponse | null> => {
    if (!user?.id) return null;

    const reviewMessage = `Skapa en ${timeframe} utvecklings√∂versikt baserat p√• min senaste aktivitet, assessments och framsteg. 
Fokusera p√• m√∂nster, framsteg och omr√•den som beh√∂ver uppm√§rksamhet.`;

    return await enhancedStefanChat({
      message: reviewMessage,
      interactionType: 'progress_review',
      includeAssessmentContext: true,
      generateRecommendations: true
    });
  }, [user, enhancedStefanChat]);

  return {
    // Core functions
    enhancedStefanChat,
    generateAssessmentFeedback,
    generateProgressReview,
    
    // State
    loading,
    lastResponse,
    
    // Utility functions
    getLastResponseInsights: () => lastResponse?.assessmentInsights || [],
    getLastResponseActions: () => lastResponse?.recommendedActions || [],
    getResponseConfidence: () => lastResponse?.confidence || 0
  };
};

/**
 * ü§ñ AI MODEL SELECTION
 * V√§ljer optimal AI-modell baserat p√• kontext och tillg√§nglighet
 */
async function selectOptimalAIModel(
  forceModel?: 'openai' | 'gemini' | 'auto',
  message?: string,
  promptContext?: StefanPromptContext
): Promise<'openai' | 'gemini'> {
  
  if (forceModel && forceModel !== 'auto') {
    return forceModel;
  }

  try {
    // Kontrollera AI-tillg√§nglighet
    const { data } = await supabase.functions.invoke('check-ai-availability');
    
    if (data?.openai && data?.gemini) {
      // B√•da tillg√§ngliga - v√§lj baserat p√• kontext
      if (message && message.length > 2000) {
        return 'gemini'; // B√§ttre f√∂r l√•nga texter
      }
      
      if (promptContext?.assessmentInsights && promptContext.assessmentInsights.length > 1000) {
        return 'openai'; // B√§ttre f√∂r komplexa analyser
      }
      
      return 'openai'; // Default till OpenAI f√∂r kvalitet
    }
    
    if (data?.openai) return 'openai';
    if (data?.gemini) return 'gemini';
    
  } catch (error) {
    console.warn('AI availability check failed, defaulting to OpenAI:', error);
  }
  
  return 'openai'; // Fallback
}

/**
 * üîÑ AI REQUEST WITH FALLBACK
 * K√∂r AI-f√∂rfr√•gan med fallback mellan modeller
 */
async function executeAIRequestWithFallback(
  primaryModel: 'openai' | 'gemini',
  promptContext: StefanPromptContext,
  options: StefanChatOptions
) {
  const fallbackModel = primaryModel === 'openai' ? 'gemini' : 'openai';
  
  try {
    // F√∂rs√∂k med prim√§r modell
    const response = await callAIModel(primaryModel, promptContext, options);
    return {
      ...response,
      modelUsed: primaryModel,
      fallbackUsed: false
    };
    
  } catch (primaryError) {
    console.warn(`Primary AI model (${primaryModel}) failed, trying fallback:`, primaryError);
    
    try {
      // Fallback till sekund√§r modell
      const response = await callAIModel(fallbackModel, promptContext, options);
      return {
        ...response,
        modelUsed: fallbackModel,
        fallbackUsed: true
      };
      
    } catch (fallbackError) {
      console.error('Both AI models failed:', { primaryError, fallbackError });
      throw new Error('Alla AI-modeller otillg√§ngliga');
    }
  }
}

/**
 * üéØ AI MODEL CALLER
 * Anropar specifik AI-modell
 */
async function callAIModel(
  model: 'openai' | 'gemini',
  promptContext: StefanPromptContext,
  options: StefanChatOptions
) {
  const functionName = model === 'openai' ? 'stefan-ai-chat' : 'stefan-gemini-chat';
  
  const { data, error } = await supabase.functions.invoke(functionName, {
    body: {
      message: options.message,
      promptContext: promptContext,
      interactionType: options.interactionType,
      includeAssessmentContext: options.includeAssessmentContext,
      generateRecommendations: options.generateRecommendations
    }
  });

  if (error) throw error;
  return data;
}

/**
 * üöÄ ENHANCE AI RESPONSE
 * F√∂rb√§ttrar AI-svaret med analys och rekommendationer
 */
async function enhanceAIResponse(
  aiResponse: any,
  promptContext: StefanPromptContext,
  options: StefanChatOptions
) {
  const insights: string[] = [];
  const actions: string[] = [];
  
  // Extrahera insikter fr√•n assessment-kontext
  if (promptContext.assessmentInsights) {
    insights.push('Baserat p√• din assessment-historik');
    insights.push('Kopplar till dina tidigare utvecklingsomr√•den');
  }
  
  // Generera rekommendationer om beg√§rt
  if (options.generateRecommendations) {
    actions.push('Forts√§tt med daglig reflektion');
    actions.push('Boka in tid f√∂r utvecklingsaktiviteter');
    actions.push('F√∂lj upp med ny assessment inom 2 veckor');
  }
  
  // Ber√§kna confidence baserat p√• kontext
  const confidence = calculateResponseConfidence(promptContext, aiResponse);
  
  return {
    message: aiResponse.message || aiResponse.response,
    insights,
    actions,
    confidence
  };
}

/**
 * üìä CONFIDENCE CALCULATOR
 * Ber√§knar tillf√∂rlitlighet f√∂r AI-svar
 */
function calculateResponseConfidence(
  promptContext: StefanPromptContext,
  aiResponse: any
): number {
  let confidence = 0.5; // Base confidence
  
  // √ñka confidence med assessment-data
  if (promptContext.assessmentInsights) confidence += 0.2;
  if (promptContext.clientContext) confidence += 0.15;
  if (promptContext.contextualMemories) confidence += 0.1;
  
  // Justera baserat p√• svarsl√§ngd och struktur
  if (aiResponse.message && aiResponse.message.length > 200) confidence += 0.05;
  
  return Math.min(confidence, 1.0);
}

/**
 * üìù LOG INTERACTION
 * Loggar Stefan-interaktion f√∂r analytics och f√∂rb√§ttring
 */
async function logStefanInteraction(
  response: EnhancedStefanResponse,
  options: StefanChatOptions
) {
  try {
    await supabase.functions.invoke('log-stefan-interaction', {
      body: {
        response,
        options,
        timestamp: new Date().toISOString()
      }
    });
  } catch (error) {
    console.warn('Failed to log Stefan interaction:', error);
  }
}

/**
 * üÜò FALLBACK TO STANDARD STEFAN
 * Fallback till standard Stefan vid totalt fel
 */
async function fallbackToStandardStefan(
  options: StefanChatOptions
): Promise<EnhancedStefanResponse | null> {
  try {
    const { data } = await supabase.functions.invoke('stefan-ai-chat', {
      body: {
        message: options.message,
        interaction_type: options.interactionType || 'chat'
      }
    });

    return {
      message: data?.message || "Stefan √§r tillf√§lligt otillg√§nglig.",
      contextUsed: {} as StefanPromptContext,
      aiModel: 'openai',
      responseTime: 0,
      assessmentInsights: [],
      recommendedActions: [],
      confidence: 0.3,
      fallbackUsed: true
    };
    
  } catch (error) {
    console.error('Even fallback Stefan failed:', error);
    return null;
  }
}